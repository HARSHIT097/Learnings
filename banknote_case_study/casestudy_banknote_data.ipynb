{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "casestudy_banknote_data.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCew_yK-rutS"
      },
      "source": [
        "Banknote Case Study\r\n",
        "\r\n",
        "A new function named decision_tree() was developed to manage the application of the CART algorithm, first creating the tree from the training dataset, then using the tree to make predictions on a test dataset.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUWDGQKCrVqj",
        "outputId": "d6f30e67-5fd0-4d90-ca6d-ff63eaa8be64"
      },
      "source": [
        "# CART on the Bank Note dataset\r\n",
        "from random import seed\r\n",
        "from random import randrange\r\n",
        "from csv import reader\r\n",
        "\r\n",
        "# Load a CSV file\r\n",
        "def load_csv(filename):\r\n",
        "\tfile = open(filename, \"rt\")\r\n",
        "\tlines = reader(file)\r\n",
        "\tdataset = list(lines)\r\n",
        "\treturn dataset\r\n",
        "\r\n",
        "# Convert string column to float\r\n",
        "def str_column_to_float(dataset, column):\r\n",
        "\tfor row in dataset:\r\n",
        "\t\trow[column] = float(row[column].strip())\r\n",
        "\r\n",
        "# Split a dataset into k folds\r\n",
        "def cross_validation_split(dataset, n_folds):\r\n",
        "\tdataset_split = list()\r\n",
        "\tdataset_copy = list(dataset)\r\n",
        "\tfold_size = int(len(dataset) / n_folds)\r\n",
        "\tfor i in range(n_folds):\r\n",
        "\t\tfold = list()\r\n",
        "\t\twhile len(fold) < fold_size:\r\n",
        "\t\t\tindex = randrange(len(dataset_copy))\r\n",
        "\t\t\tfold.append(dataset_copy.pop(index))\r\n",
        "\t\tdataset_split.append(fold)\r\n",
        "\treturn dataset_split\r\n",
        "\r\n",
        "# Calculate accuracy percentage\r\n",
        "def accuracy_metric(actual, predicted):\r\n",
        "\tcorrect = 0\r\n",
        "\tfor i in range(len(actual)):\r\n",
        "\t\tif actual[i] == predicted[i]:\r\n",
        "\t\t\tcorrect += 1\r\n",
        "\treturn correct / float(len(actual)) * 100.0\r\n",
        "\r\n",
        "# Evaluate an algorithm using a cross validation split\r\n",
        "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\r\n",
        "\tfolds = cross_validation_split(dataset, n_folds)\r\n",
        "\tscores = list()\r\n",
        "\tfor fold in folds:\r\n",
        "\t\ttrain_set = list(folds)\r\n",
        "\t\ttrain_set.remove(fold)\r\n",
        "\t\ttrain_set = sum(train_set, [])\r\n",
        "\t\ttest_set = list()\r\n",
        "\t\tfor row in fold:\r\n",
        "\t\t\trow_copy = list(row)\r\n",
        "\t\t\ttest_set.append(row_copy)\r\n",
        "\t\t\trow_copy[-1] = None\r\n",
        "\t\tpredicted = algorithm(train_set, test_set, *args)\r\n",
        "\t\tactual = [row[-1] for row in fold]\r\n",
        "\t\taccuracy = accuracy_metric(actual, predicted)\r\n",
        "\t\tscores.append(accuracy)\r\n",
        "\treturn scores\r\n",
        "\r\n",
        "# Split a dataset based on an attribute and an attribute value\r\n",
        "def test_split(index, value, dataset):\r\n",
        "\tleft, right = list(), list()\r\n",
        "\tfor row in dataset:\r\n",
        "\t\tif row[index] < value:\r\n",
        "\t\t\tleft.append(row)\r\n",
        "\t\telse:\r\n",
        "\t\t\tright.append(row)\r\n",
        "\treturn left, right\r\n",
        "\r\n",
        "# Calculate the Gini index for a split dataset\r\n",
        "def gini_index(groups, classes):\r\n",
        "\t# count all samples at split point\r\n",
        "\tn_instances = float(sum([len(group) for group in groups]))\r\n",
        "\t# sum weighted Gini index for each group\r\n",
        "\tgini = 0.0\r\n",
        "\tfor group in groups:\r\n",
        "\t\tsize = float(len(group))\r\n",
        "\t\t# avoid divide by zero\r\n",
        "\t\tif size == 0:\r\n",
        "\t\t\tcontinue\r\n",
        "\t\tscore = 0.0\r\n",
        "\t\t# score the group based on the score for each class\r\n",
        "\t\tfor class_val in classes:\r\n",
        "\t\t\tp = [row[-1] for row in group].count(class_val) / size\r\n",
        "\t\t\tscore += p * p\r\n",
        "\t\t# weight the group score by its relative size\r\n",
        "\t\tgini += (1.0 - score) * (size / n_instances)\r\n",
        "\treturn gini\r\n",
        "\r\n",
        "# Select the best split point for a dataset\r\n",
        "def get_split(dataset):\r\n",
        "\tclass_values = list(set(row[-1] for row in dataset))\r\n",
        "\tb_index, b_value, b_score, b_groups = 999, 999, 999, None\r\n",
        "\tfor index in range(len(dataset[0])-1):\r\n",
        "\t\tfor row in dataset:\r\n",
        "\t\t\tgroups = test_split(index, row[index], dataset)\r\n",
        "\t\t\tgini = gini_index(groups, class_values)\r\n",
        "\t\t\tif gini < b_score:\r\n",
        "\t\t\t\tb_index, b_value, b_score, b_groups = index, row[index], gini, groups\r\n",
        "\treturn {'index':b_index, 'value':b_value, 'groups':b_groups}\r\n",
        "\r\n",
        "# Create a terminal node value\r\n",
        "def to_terminal(group):\r\n",
        "\toutcomes = [row[-1] for row in group]\r\n",
        "\treturn max(set(outcomes), key=outcomes.count)\r\n",
        "\r\n",
        "# Create child splits for a node or make terminal\r\n",
        "def split(node, max_depth, min_size, depth):\r\n",
        "\tleft, right = node['groups']\r\n",
        "\tdel(node['groups'])\r\n",
        "\t# check for a no split\r\n",
        "\tif not left or not right:\r\n",
        "\t\tnode['left'] = node['right'] = to_terminal(left + right)\r\n",
        "\t\treturn\r\n",
        "\t# check for max depth\r\n",
        "\tif depth >= max_depth:\r\n",
        "\t\tnode['left'], node['right'] = to_terminal(left), to_terminal(right)\r\n",
        "\t\treturn\r\n",
        "\t# process left child\r\n",
        "\tif len(left) <= min_size:\r\n",
        "\t\tnode['left'] = to_terminal(left)\r\n",
        "\telse:\r\n",
        "\t\tnode['left'] = get_split(left)\r\n",
        "\t\tsplit(node['left'], max_depth, min_size, depth+1)\r\n",
        "\t# process right child\r\n",
        "\tif len(right) <= min_size:\r\n",
        "\t\tnode['right'] = to_terminal(right)\r\n",
        "\telse:\r\n",
        "\t\tnode['right'] = get_split(right)\r\n",
        "\t\tsplit(node['right'], max_depth, min_size, depth+1)\r\n",
        "\r\n",
        "# Build a decision tree\r\n",
        "def build_tree(train, max_depth, min_size):\r\n",
        "\troot = get_split(train)\r\n",
        "\tsplit(root, max_depth, min_size, 1)\r\n",
        "\treturn root\r\n",
        "\r\n",
        "# Make a prediction with a decision tree\r\n",
        "def predict(node, row):\r\n",
        "\tif row[node['index']] < node['value']:\r\n",
        "\t\tif isinstance(node['left'], dict):\r\n",
        "\t\t\treturn predict(node['left'], row)\r\n",
        "\t\telse:\r\n",
        "\t\t\treturn node['left']\r\n",
        "\telse:\r\n",
        "\t\tif isinstance(node['right'], dict):\r\n",
        "\t\t\treturn predict(node['right'], row)\r\n",
        "\t\telse:\r\n",
        "\t\t\treturn node['right']\r\n",
        "\r\n",
        "# Classification and Regression Tree Algorithm\r\n",
        "def decision_tree(train, test, max_depth, min_size):\r\n",
        "\ttree = build_tree(train, max_depth, min_size)\r\n",
        "\tpredictions = list()\r\n",
        "\tfor row in test:\r\n",
        "\t\tprediction = predict(tree, row)\r\n",
        "\t\tpredictions.append(prediction)\r\n",
        "\treturn(predictions)\r\n",
        "\r\n",
        "# Test CART on Bank Note dataset\r\n",
        "seed(1)\r\n",
        "# load and prepare data\r\n",
        "filename = 'data_banknote_authentication.csv'\r\n",
        "dataset = load_csv(filename)\r\n",
        "# convert string attributes to integers\r\n",
        "for i in range(len(dataset[0])):\r\n",
        "\tstr_column_to_float(dataset, i)\r\n",
        "# evaluate algorithm\r\n",
        "n_folds = 5\r\n",
        "max_depth = 5\r\n",
        "min_size = 10\r\n",
        "scores = evaluate_algorithm(dataset, decision_tree, n_folds, max_depth, min_size)\r\n",
        "print('Scores: %s' % scores)\r\n",
        "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scores: [96.35036496350365, 97.08029197080292, 97.44525547445255, 98.17518248175182, 97.44525547445255]\n",
            "Mean Accuracy: 97.299%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gBpOn-0sCTz"
      },
      "source": [
        "The example uses the max tree depth of 5 layers and the minimum number of rows per node to 10. These parameters to CART were chosen with a little experimentation, but are by no means are they optimal.\r\n",
        "\r\n",
        "Running the example prints the average classification accuracy on each fold as well as the average performance across all folds.\r\n",
        "\r\n",
        "You can see that CART and the chosen configuration achieved a mean classification accuracy of about 97% which is dramatically better than the Zero Rule algorithm that achieved 50% accuracy."
      ]
    }
  ]
}